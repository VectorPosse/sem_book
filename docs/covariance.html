<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Covariance | Demystifying Structural Equation Modeling</title>
<meta name="author" content="Jonathan Amburgey and Sean Raleigh, Westminster College (Salt Lake City, UT)">
<meta name="description" content="3.1 Calculating covariance The last chapter was about variance, which measures the spread of a single variable. Now we extend this idea to pairs of variables. We say that two variables “co-vary”...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Chapter 3 Covariance | Demystifying Structural Equation Modeling">
<meta property="og:type" content="book">
<meta property="og:url" content="https://vectorposse.github.io/sem_book/covariance.html">
<meta property="og:description" content="3.1 Calculating covariance The last chapter was about variance, which measures the spread of a single variable. Now we extend this idea to pairs of variables. We say that two variables “co-vary”...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3 Covariance | Demystifying Structural Equation Modeling">
<meta name="twitter:description" content="3.1 Calculating covariance The last chapter was about variance, which measures the spread of a single variable. Now we extend this idea to pairs of variables. We say that two variables “co-vary”...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Demystifying Structural Equation Modeling</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction</a></li>
<li><a class="" href="variables.html"><span class="header-section-number">1</span> Variables and measurement</a></li>
<li><a class="" href="variance.html"><span class="header-section-number">2</span> Variance</a></li>
<li><a class="active" href="covariance.html"><span class="header-section-number">3</span> Covariance</a></li>
<li><a class="" href="simple.html"><span class="header-section-number">4</span> Simple regression</a></li>
<li><a class="" href="multiple.html"><span class="header-section-number">5</span> Multiple regression</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">6</span> Mediation</a></li>
<li><a class="" href="path.html"><span class="header-section-number">7</span> Path analysis</a></li>
<li><a class="" href="latent.html"><span class="header-section-number">8</span> Latent variables</a></li>
<li><a class="" href="cfa.html"><span class="header-section-number">9</span> Confirmatory factor analysis</a></li>
<li><a class="" href="sem.html"><span class="header-section-number">10</span> Structural equation models</a></li>
<li><a class="" href="scm.html"><span class="header-section-number">11</span> Structural causal models</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="appendix-rules.html"><span class="header-section-number">A</span> Variance/covariance rules</a></li>
<li><a class="" href="appendix-lisrel.html"><span class="header-section-number">B</span> LISREL notation</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/VectorPosse/sem_book">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="covariance" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Covariance<a class="anchor" aria-label="anchor" href="#covariance"><i class="fas fa-link"></i></a>
</h1>
<div class="inline-figure"><img src="graphics/covariance.png" width="204" style="display: block; margin: auto;"></div>
<div id="covariance-calculating" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Calculating covariance<a class="anchor" aria-label="anchor" href="#covariance-calculating"><i class="fas fa-link"></i></a>
</h2>
<p>The last chapter was about variance, which measures the spread of a single variable. Now we extend this idea to pairs of variables.</p>
<p>We say that two variables “co-vary” when the spread of one variable is related to the spread of another variable. This relationship represents an <em>association</em> between the two variables.</p>
<p>We’ll call our two variables <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span>. To keep things simple, let’s assume that we have already mean centered our variables.</p>
<div class="rmdnote">
<p>If <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> are already mean centered, then what are <span class="math inline">\(\overline{X_{1}}\)</span> and <span class="math inline">\(\overline{X_{2}}\)</span>?</p>
</div>
<p>As we did in the last chapter with variance, we’ll build up the calculation of covariance step-by-step using a table to keep track of intermediate quantities we need.</p>
<p>Here are two variables (with <span class="math inline">\(n = 7\)</span>) that have been mean centered:</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="right"><span class="math inline">\(X_{1}\)</span></th>
<th align="right"><span class="math inline">\(X_{2}\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">-1</td>
<td align="right">-2</td>
</tr>
<tr class="even">
<td align="right">-2</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">-2</td>
</tr>
<tr class="even">
<td align="right">-3</td>
<td align="right">-1</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">-1</td>
<td align="right">-2</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">3</td>
</tr>
</tbody>
</table></div>
<div class="rmdnote">
<p>Check that the mean of both columns is truly zero.</p>
</div>
<p>Something interesting happens when we look at the product <span class="math inline">\(X_{1}X_{2}\)</span>.</p>
<div class="rmdnote">
<p>If <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> both lie above their means, they are both positive numbers. Therefore, their product is positive.</p>
<p>What if both <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> lie below their means? What do we know about their values individually and what do we know about their product?</p>
</div>
<p>Here is the chart again, but with the products listed in a new column:</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="right"><span class="math inline">\(X_{1}\)</span></th>
<th align="right"><span class="math inline">\(X_{2}\)</span></th>
<th align="right"><span class="math inline">\(X_{1}X_{2}\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">-2</td>
<td align="right">2</td>
<td align="right">-4</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">-2</td>
<td align="right">-4</td>
</tr>
<tr class="even">
<td align="right">-3</td>
<td align="right">-1</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">2</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">3</td>
<td align="right">3</td>
</tr>
</tbody>
</table></div>
<p>Now we add up the products across all seven data pairs:</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="right"><span class="math inline">\(X_{1}\)</span></th>
<th align="right"><span class="math inline">\(X_{2}\)</span></th>
<th align="right"><span class="math inline">\(X_{1}X_{2}\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">-2</td>
<td align="right">2</td>
<td align="right">-4</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">-2</td>
<td align="right">-4</td>
</tr>
<tr class="even">
<td align="right">-3</td>
<td align="right">-1</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">2</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">3</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="right"></td>
<td align="right">Sum: 10</td>
</tr>
</tbody>
</table></div>
<p>So when <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> tend to have similar values (both positive or both negative), their product is usually positive. It’s not true of every pair of values in the table above; some products are negative. But the majority are positive. Therefore, the sum of all such products will be positive.</p>
<p>We’re almost there. Just like we wanted the average squared deviation to calculate the variance, here we want the average of the products from the third column above. And just like in the case of variance, it’s not <em>quite</em> the average we calculate. Instead of dividing by <span class="math inline">\(n\)</span>, we divide by <span class="math inline">\(n - 1\)</span> for exactly the same esoteric reason. In our example, there are 7 data points (in other words, 7 rows of data), so we divide by 6.</p>
<p>Putting this all together:</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="right"><span class="math inline">\(X_{1}\)</span></th>
<th align="right"><span class="math inline">\(X_{2}\)</span></th>
<th align="right"><span class="math inline">\(X_{1}X_{2}\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">-2</td>
<td align="right">2</td>
<td align="right">-4</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">-2</td>
<td align="right">-4</td>
</tr>
<tr class="even">
<td align="right">-3</td>
<td align="right">-1</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">2</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">3</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="right"></td>
<td align="right">Sum: 10</td>
</tr>
<tr class="odd">
<td align="right"></td>
<td align="right"></td>
<td align="right">Covariance: 10/6 = <span class="math inline">\(\boxed{1.67}\)</span>
</td>
</tr>
</tbody>
</table></div>
<p>In our diagrams, the covariance of two variables is indicated by a curved, double-headed arrow pointing at both boxes and labeled with the value of the covariance, like this:</p>
<div class="inline-figure"><img src="graphics/covariance_labeled.png" width="204" style="display: block; margin: auto;"></div>
<p>Note that we still include the variances of each of the individual variables. They are still important to us. We just have one new type of arrow now.</p>
<div class="rmdnote">
<p>Verify that the variances in the diagram are correct for our example. You can do it by hand if you want, but using R is fine too.</p>
</div>
<p>Here is the final formula for covariance, written as <span class="math inline">\(Cov\left(X_{1}, X_{2}\right)\)</span>. This works for all pairs of variables, even if they aren’t mean centered. The terms <span class="math inline">\(\left(X_{1} - \overline{X_1}\right)\)</span> and <span class="math inline">\(\left(X_{2} - \overline{X_2}\right)\)</span> do the mean centering:</p>
<div class="rmdimportant">
<p><span class="math display">\[
Cov\left(X_{1}, X_{2}\right) = \frac{\sum \left(X_{1} - \overline{X_{1}}\right)\left(X_{2} - \overline{X_{2}}\right)}{n - 1}
\]</span></p>
</div>
<div class="rmdnote">
<p>Suppose <span class="math inline">\(X_{1}\)</span> tends to be above its mean when <span class="math inline">\(X_{2}\)</span> is below its mean and <span class="math inline">\(X_{1}\)</span> tends to be below its mean when <span class="math inline">\(X_{2}\)</span> is above its mean. What will the product <span class="math inline">\(\left(X_{1} - \overline{X_{1}}\right)\left(X_{2} - \overline{X_{2}}\right)\)</span> usually be? Therefore, what will the sum of all such products likely be?</p>
</div>
<p>For general variables (not necessarily mean centered), the table will actually look like this:</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th align="right"><span class="math inline">\(X_{1}\)</span></th>
<th align="right"><span class="math inline">\(X_{2}\)</span></th>
<th align="right"><span class="math inline">\(\left(X_{1} - \overline{X_{1}}\right)\)</span></th>
<th align="right"><span class="math inline">\(\left(X_{2} - \overline{X_{2}}\right)\)</span></th>
<th align="right"><span class="math inline">\(\left(X_{1} - \overline{X_{1}}\right)\left(X_{2} - \overline{X_{2}}\right)\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">17</td>
<td align="right">23</td>
<td align="right">-2</td>
<td align="right">11</td>
<td align="right">-22</td>
</tr>
<tr class="even">
<td align="right">25</td>
<td align="right">15</td>
<td align="right">6</td>
<td align="right">3</td>
<td align="right">18</td>
</tr>
<tr class="odd">
<td align="right">…</td>
<td align="right">…</td>
<td align="right">…</td>
<td align="right">…</td>
<td align="right">…</td>
</tr>
</tbody>
</table></div>
<div class="rmdnote">
<p>Calculate the covariance by hand by making a table like the one above. (These variables are <em>not</em> mean centered, so you’ll have to calculate the mean of each variable in order to fill out the third and fourth columns.)</p>
<p><span class="math inline">\(X_{3}\)</span>: 8, 10, 16, 7, 4, 3</p>
<p><span class="math inline">\(X_{4}\)</span>: 6, 5, 4, 9, 11, 7</p>
<p>Explain intuitively why the covariance is negative for these two variables.</p>
</div>
<div class="rmdnote">
<p>When calculating variance, the order of the data points does not matter. Why?</p>
<p>When calculating covariance, the order of the data points <em>does</em> matter. Why?</p>
<p>What if you keep pairs together, but rearrange the rows of the table. How does that affect the covariance?</p>
</div>
</div>
<div id="covariance-r" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Calculating covariance in R<a class="anchor" aria-label="anchor" href="#covariance-r"><i class="fas fa-link"></i></a>
</h2>
<p>Once we’ve done it by hand a few times to make sure we understand how the formula works, from here on out we can let R do the work for us:</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="op">-</span><span class="fl">2</span>, <span class="fl">2</span>, <span class="op">-</span><span class="fl">3</span>, <span class="fl">4</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>
<span class="va">X2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">2</span>, <span class="op">-</span><span class="fl">2</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="op">-</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">X1</span>, <span class="va">X2</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 1.666667</code></pre>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">10</span>, <span class="fl">16</span>, <span class="fl">7</span>, <span class="fl">4</span>, <span class="fl">3</span><span class="op">)</span>
<span class="va">X4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">5</span>, <span class="fl">4</span>, <span class="fl">9</span>, <span class="fl">11</span>, <span class="fl">7</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">X3</span>, <span class="va">X4</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -9.2</code></pre>
<p>And here’s some real world data:</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">$</span><span class="va">Temp</span>, <span class="va">airquality</span><span class="op">$</span><span class="va">Wind</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -15.27214</code></pre>
</div>
<div id="covariance-rules" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> Covariance rules<a class="anchor" aria-label="anchor" href="#covariance-rules"><i class="fas fa-link"></i></a>
</h2>
<p>We’ll think of the variance and covariance rules as one big list. We left off on <a href="./variance.html#Rule4"><strong>Rule 4</strong></a>, so now we’ll introduce <a href="#Rule5"><strong>Rule 5</strong></a>.</p>
<div class="rmdimportant">
<ul>
<li><a id="Rule5"><strong>Rule 5</strong></a></li>
</ul>
<p><span class="math display">\[
Cov(X, X) = Var(X)
\]</span></p>
</div>
<p>In words, <a href="#Rule5"><strong>Rule 5</strong></a> states that the covariance of a variable <em>with itself</em> is just the same thing as the variance of that variable. This is quite remarkable! It means that variance is really just a special case of covariance.</p>
<div class="rmdnote">
<p>Explain why <a href="#Rule5"><strong>Rule 5</strong></a> is true. (Hint: think about how you would calculate <span class="math inline">\(Cov(X, X)\)</span> using either the formula or the table—or both!)</p>
</div>
<div class="rmdimportant">
<ul>
<li><a id="Rule6"><strong>Rule 6</strong></a></li>
</ul>
<p><span class="math display">\[
Cov\left(X_{1}, X_{2}\right) = Cov\left(X_{2}, X_{1}\right)
\]</span></p>
</div>
<p>In words, we would say that covariance is <em>symmetric</em>.</p>
<div class="rmdnote">
<p>Explain why <a href="#Rule6"><strong>Rule 6</strong></a> is true. (Again, think about the formula or the table—or both!)</p>
</div>
<p>The next four rules are analogous to similar rules for variance (<a href="./variance.html#Rule1"><strong>Rule 1</strong></a>, <a href="./variance.html#Rule2"><strong>Rule 2</strong></a>, <a href="./variance.html#Rule3"><strong>Rule 3</strong></a>, and <a href="./variance.html#Rule4"><strong>Rule 4</strong></a>).</p>
<div class="rmdimportant">
<ul>
<li><a id="Rule7"><strong>Rule 7</strong></a></li>
</ul>
<p>Suppose that <span class="math inline">\(C\)</span> is a “constant” variable, meaning that it always has the same value (rather than being a variable that could contain lots of different numbers). Then,</p>
<p><span class="math display">\[
Cov\left(X, C\right) = 0
\]</span></p>
</div>
<div class="rmdnote">
<p>As always, try to explain this rule. Give an intuitive explanation of why this rule “should” be true. Then think about it computationally, thinking of either the formula or the table—or both!</p>
</div>
<div class="rmdimportant">
<ul>
<li><a id="Rule8"><strong>Rule 8</strong></a></li>
</ul>
<p><span class="math display">\[
Cov\left(X_{1} + X_{2}, X_{3}\right) = Cov\left(X_{1}, X_{3}\right) + Cov\left(X_{2}, X_{3}\right)  
\]</span></p>
</div>
<p>What you should appreciate here is that there is no longer any restriction on the relationships among the variables involved. <a href="./variance.html#Rule2"><strong>Rule 2</strong></a> only worked when the two variables were independent. On the other hand, <a href="#Rule8"><strong>Rule 8</strong></a> works for any combination of variables, no matter their relation.</p>
<p>Even more satisfying is this next rule:</p>
<div class="rmdimportant">
<ul>
<li><a id="Rule9"><strong>Rule 9</strong></a></li>
</ul>
<p><span class="math display">\[
Cov\left(X_{1} - X_{2}, X_{3}\right) = Cov\left(X_{1}, X_{3}\right) - Cov\left(X_{2}, X_{3}\right)  
\]</span></p>
</div>
<p>Yay! The minus sign behaves sensibly now! Of course, since covariances can be positive or negative (unlike variances which are always positive!) we can more safely subtract two of them without worry. And this rule, like <a href="#Rule8"><strong>Rule 8</strong></a>, does not depend on <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> being independent. They can be any two variables.</p>
<p>There are versions of these rules with the addition or subtraction on the other side, but these are just minor variations of <a href="#Rule8"><strong>Rule 8</strong></a> and <a href="#Rule9"><strong>Rule 9</strong></a>, so they’re not worth mentioning as a separate rule. Remember that covariance is symmetric, so you can always swap things on the left and right of the comma.</p>
<div class="rmdimportant">
<p><span class="math display">\[
Cov\left(X_{1}, X_{2} \pm X_{3}\right) = Cov\left(X_{1}, X_{2}\right) \pm Cov\left(X_{1}, X_{3}\right)  
\]</span></p>
</div>
<div class="rmdimportant">
<ul>
<li><a id="Rule10"><strong>Rule 10</strong></a></li>
</ul>
<p>If <span class="math inline">\(a\)</span> is any number,</p>
<p><span class="math display">\[
Cov\left(a X_{1}, X_{2}\right) = a Cov\left(X_{1}, X_{2}\right) =  Cov\left(X_{1}, a X_{2}\right)  
\]</span></p>
</div>
<p>This rule is also very sensible. Instead of <a href="./variance.html#Rule4"><strong>Rule 4</strong></a> that takes a number <span class="math inline">\(a\)</span> and pulls out an <span class="math inline">\(a^{2}\)</span>, <a href="#Rule10"><strong>Rule 10</strong></a> just pulls out a single factor of <span class="math inline">\(a\)</span> (from either slot).</p>
<p>Just a couple more rules. We were talking about independence in conjunction with <a href="#Rule8"><strong>Rule 8</strong></a> and <a href="#Rule9"><strong>Rule 9</strong></a>. That leads directly to an interesting and super-important rule:</p>
<div class="rmdimportant">
<ul>
<li><a id="Rule11"><strong>Rule 11</strong></a></li>
</ul>
<p>If <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> are independent, then</p>
<p><span class="math display">\[
Cov\left(X_{1}, X_{2}\right) = 0
\]</span></p>
</div>
<div class="rmdnote">
<p>Why is <a href="#Rule11"><strong>Rule 11</strong></a> true, intuitively?</p>
<p>It’s interesting to note that this rule only works one way. In other words, if you know that two variables are independent, then you can conclude their covariance is zero. However, if you know the covariance is zero, that doesn’t necessarily mean that the two variables are independent. We’ll see an example of this later in the chapter.</p>
</div>
<p>Finally, one rule to rule them all:</p>
<div class="rmdimportant">
<ul>
<li><a id="Rule12"><strong>Rule 12</strong></a></li>
</ul>
<p>For <em>any</em> two variables <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span>:</p>
<p><span class="math display">\[
Var(aX_{1} + bX_{2}) =
    a^2Var(X_{1}) + b^2Var(X_{2}) + 2abCov(X_{1}, X_{2})
\]</span></p>
</div>
<p>This brings practically everything we know together into one rule!</p>
<div class="rmdnote">
<p>Proving <a href="#Rule12"><strong>Rule 12</strong></a> will give us good practice with the type of manipulation we’ll need to do in future chapters. So here goes. For the first few steps, you name what rule we’re invoking. Then, you’ll pick up the thread and follow it through the last few steps on your own.</p>
<p><span class="math display">\[\begin{align}
Var(aX_{1} + bX_{2}) &amp;= Cov(aX_{1} + bX_{2}, aX_{1} + bX_{2}) \\
    &amp;= Cov(aX_{1} + bX_{2}, aX_{1}) + Cov(aX_{1} + bX_{2}, bX_{2}) \\
    &amp;=  Cov(aX_{1}, aX_{1}) +
        Cov(bX_{2}, aX_{1}) + \\
    &amp;   \qquad Cov(aX_{1}, bX_{2}) +
        Cov(bX_{2}, bX_{2}) \\
    &amp;= \quad ???
\end{align}\]</span></p>
</div>
<p>You’ll need these rules to do calculations in future chapters. Rather than having to search for them in Chapter <a href="variance.html#variance">2</a> and this chapter, we’ve gathered up all the rules in one convenient place in Appendix <a href="appendix-rules.html#appendix-rules">A</a>.</p>
</div>
<div id="covariance-correlation" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> Correlation<a class="anchor" aria-label="anchor" href="#covariance-correlation"><i class="fas fa-link"></i></a>
</h2>
<p>The pros and cons for calculating covariance are similar to those for variance. The mathematics is much nicer for covariance, but we lose interpretability.</p>
<div class="rmdnote">
<p>Let’s suppose that <span class="math inline">\(X_{1}\)</span> measures salary in dollars and <span class="math inline">\(X_{2}\)</span> measures years of education. We would expect there to be some association between these variables, so we calculate the covariance. What is the unit of measurement of the resulting number?</p>
</div>
<p>The solution to the problem here is not as simple as it was for variance. Since variance had squared units, all we had to do was take the square root. Covariance has a weird product of units, so we have to do something more clever.</p>
<p>Following up on the activity above, let’s suppose we have a covariance with units of “dollar-years”. If we divide by a number expressed in dollars, we get rid of those units and we’re left with years. But that seems unsatisfying; covariance should express something about both variables that went into it. Likewise, it makes no sense to divide by a number expressed in years as that would leave us just with dollars.</p>
<p>The solution to the dilemma is to accept that we aren’t going to be able to keep any units in a meaningful way. Therefore, what we want is something <em>standardized</em>, meaning that it has no units.</p>
<div class="rmdnote">
<p>If <span class="math inline">\(X_{1}\)</span> is expressed in dollars, can you think of a statistic that measures spread and is also in units of dollars?</p>
<p>Likewise, if <span class="math inline">\(X_{2}\)</span> is measured in years, what statistic that measures spread is also in units of years?</p>
</div>
<p>The previous activity gives us an idea. What if we divide the covariance by <em>both</em> the standard deviation of <span class="math inline">\(X_{1}\)</span> <em>and</em> the standard deviation of <span class="math inline">\(X_{2}\)</span>?</p>
<p><span class="math display">\[
\frac{Cov(X_{1},X_{2})}{SD(X_{1}) SD(X_{2})}
\]</span></p>
<p>Sometimes it’s written like this:</p>
<p><span class="math display">\[
\frac{Cov(X_{1},X_{2})}{\sqrt{Var(X_{1})} \sqrt{Var(X_{2})}}
\]</span>
But that’s the same thing, right?</p>
<p>This quantity has no units. We call this the <em>correlation</em> between <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span>. We’ll either write
<span class="math display">\[
Corr(X_{1}, X_{2})
\]</span>
or, if we need to be more concise,
<span class="math display">\[
r_{X_{1}X_{2}}
\]</span></p>
<p>Yes, this is the same as the correlation coefficient you learned about in your intro stats class, although it wasn’t likely presented to you quite this way.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Karl Pearson is credited with inventing the correlation coefficient. Pearson was a life-long eugenicist and a proponent of using “science” to prove that some races were superior to others. It important to disentangle the truly valuable notion of correlation from the discredited hands that may have first written it down. Therefore, we will not be referring to it in this text as the Pearson correlation coefficient.&lt;/p&gt;"><sup>11</sup></a></p>
<p>One great thing about correlation is that it has no units, so it serves as a sort of “universal” measure of how two variables co-vary. But the best part is that it has a nice intuitive meaning precisely because it factors out the pieces of the covariance that are only there because of the spread of the two variables individually. In other words, the fact that <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> have their own variability actually <em>complicates</em> the notion of covariance. Those individual variances “corrupt” the interpretation of covariance. But after excising them, all that’s left in the correlation is the “pure” part of the covariance that expresses the relationship or association between <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span>.</p>
</div>
<div id="covariance-standardized" class="section level2" number="3.5">
<h2>
<span class="header-section-number">3.5</span> Covariance with standardized data<a class="anchor" aria-label="anchor" href="#covariance-standardized"><i class="fas fa-link"></i></a>
</h2>
<p>In the last chapter, you showed that the variance of a standardized variable was 1. What is the covariance between two standardized variables?</p>
<div class="rmdnote">
<p>Let’s standardize both <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span>. To make the math a little easier, we’ll use similar notation to what we used at the end of the last chapter.</p>
<p><span class="math inline">\(M_{1} = \overline{X_{1}}\)</span></p>
<p><span class="math inline">\(S_{1} = SD(X_{1})\)</span></p>
<p><span class="math inline">\(M_{2} = \overline{X_{2}}\)</span></p>
<p><span class="math inline">\(S_{2} = SD(X_{2})\)</span></p>
<p>And we’ll write the z-scores in a way that is more amenable to mathematical manipulation (like before):</p>
<p><span class="math display">\[
Z_{1} = \frac{1}{S_{1}}\left(X_{1} - M_{1}\right)
\]</span></p>
<p><span class="math display">\[
Z_{2} = \frac{1}{S_{2}}\left(X_{2} - M_{2}\right)
\]</span></p>
<p>This looks a little more intimidating, but if you apply the rules, it works out:</p>
<p><span class="math display">\[\begin{align}
Cov(Z_{1}, Z_{2}) &amp;= Cov\left( \frac{1}{S_{1}}\left(X_{1} - M_{1}\right), \frac{1}{S_{2}}\left(X_{2} - M_{2}\right) \right) \\
    &amp;= \quad ???
\end{align}\]</span></p>
<p>Work this out. Take your time. Apply the rules carefully. So that you know what you’re aiming for, you should get</p>
<p><span class="math display">\[
Cov(Z_{1}, Z_{2}) = \frac{Cov\left( X_{1}, X_{2} \right)}{S_{1} S_{2}}
\]</span></p>
<p>Okay, now remember that <span class="math inline">\(S_{1}\)</span> is just a convenient substitute for <span class="math inline">\(SD(X_{1})\)</span> and <span class="math inline">\(S_{2}\)</span> is just a substitute for <span class="math inline">\(SD(X_{2})\)</span>. Wait, does that answer look familiar?</p>
</div>
<p>This is cool! Correlation is simply the covariance of two variables after they’ve been standardized.</p>
<p>This also reinforces the earlier comment about interpreting covariance after removing the extraneous influence of the spread of the individual variables. Standardizing variables makes the spread all all variables 1, so their covariance is now a pure representation of just the association between them.</p>
<p>You probably remember from intro stats that correlation takes on values between -1 and 1. That fact is not obvious from the formula we have. Why should the fraction
<span class="math display">\[
\frac{Cov(X_{1},X_{2})}{SD(X_{1}) SD(X_{2})}
\]</span>
be bounded by -1 and 1?</p>
<div class="rmdnote">
<p>Let’s go back to standardized variable to keep things simple. The correlation is just the covariance of two standardized variables:</p>
<p><span class="math display">\[
Corr(X_{1}, X_{2}) = Cov(Z_{1}, Z_{2})
\]</span></p>
<p>Use the rules to calculate this:</p>
<p><span class="math display">\[
Var(Z_{1} + Z_{2})
\]</span></p>
<p>Remember that <span class="math inline">\(Z_{1}\)</span> and <span class="math inline">\(Z_{2}\)</span> are not necessarily independent. (In fact, we hope they are not. Otherwise, why do we care about their correlation? It would be zero!) So you need <a href="#Rule12"><strong>Rule 12</strong></a>, not <a href="./variance.html#Rule2"><strong>Rule 2</strong></a>. Keep manipulating until you get
<span class="math display">\[
2 + 2Corr(X_{1}, X_{2})
\]</span></p>
<p>Since variances are always non-negative, we now know that</p>
<p><span class="math display">\[
0 \leq 2 + 2Corr(X_{1}, X_{2})
\]</span>
Solve this inequality for <span class="math inline">\(Corr(X_{1}, X_{2})\)</span>.</p>
<p>Now follow the exact same steps for
<span class="math display">\[
Var(Z_{1} - Z_{2})
\]</span></p>
<p>Very little should change in your answer, but there is one small change. Again, solve the resulting inequality. (Don’t forget the key rule when working with inequalities that multiplying or dividing by a negative number changes the direction of the inequality.)</p>
</div>
<p>Here is a fact we will state without proof:</p>
<div class=".{rmdimportant}">
<p>Correlation is only interpretable as the strength of <strong>linear</strong> associations.</p>
</div>
<p>Why is this? Basically, it boils down to the fact that a “perfect” correlation of 1 or -1 is only achievable when data points lie on a perfectly straight line. Therefore, thinking of correlation as lying between 0 and 1 (or 0 and -1) is only sensible if you are judging how close points are to lying on a straight line. We’ll see examples of this in the next section when we plot some data.</p>
<p>To calculation correlation in R, use the <code>cor</code> command:</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">$</span><span class="va">Temp</span>, <span class="va">airquality</span><span class="op">$</span><span class="va">Wind</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -0.4579879</code></pre>
<div class="rmdnote">
<p>Use R to confirm that the number above is the covariance divided by the product of the standard deviations.</p>
</div>
</div>
<div id="covariance-visualizing" class="section level2" number="3.6">
<h2>
<span class="header-section-number">3.6</span> Visualizing correlation<a class="anchor" aria-label="anchor" href="#covariance-visualizing"><i class="fas fa-link"></i></a>
</h2>
<p>Covariance is hard to interpret, so when we’re visualizing data and we want to understand any association that might exist between two variables, correlation is a much better statistic to calculate. Let’s see how correlation relates to the graph of two variables.</p>
<p>Before getting into the graphing, we will need to load some packages. The <code>tidyverse</code> is a whole set of commonly used packages that will allow us to work with data frames (or “tibbles” as the cool kids are calling them) and make graphs. Be sure to load the package by typing the following in R before going any further:</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></code></pre></div>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──</code></pre>
<pre><code>## ✔ ggplot2 3.3.6     ✔ purrr   0.3.4
## ✔ tibble  3.1.7     ✔ dplyr   1.0.9
## ✔ tidyr   1.2.0     ✔ stringr 1.4.0
## ✔ readr   2.1.2     ✔ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<p>In fact, from here on out, we’ll start each chapter by loading any necessary libraries in R that we’ll need.</p>
<p>The standard graph of two numerical variables is a scatterplot. Let’s start with a straight line relationship. First, we define two variables. We’ll use some shortcuts here to make our lives a little easier. The <code>seq</code> command just generates a sequence of numbers.</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">9</span><span class="op">)</span>
<span class="va">X5</span></code></pre></div>
<pre><code>## [1] 1 2 3 4 5 6 7 8 9</code></pre>
<p>Then we can establish a linear relationship just by declaring one in a formula:</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X6</span> <span class="op">&lt;-</span> <span class="fl">3</span> <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">X5</span>
<span class="va">X6</span></code></pre></div>
<pre><code>## [1] 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5</code></pre>
<p>To put both variables into the same graph, it helps to make them both columns in a single tibble.</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">linear_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span><span class="va">X5</span>, <span class="va">X6</span><span class="op">)</span>
<span class="va">linear_data</span></code></pre></div>
<pre><code>## # A tibble: 9 × 2
##      X5    X6
##   &lt;int&gt; &lt;dbl&gt;
## 1     1   3.5
## 2     2   4  
## 3     3   4.5
## 4     4   5  
## 5     5   5.5
## 6     6   6  
## 7     7   6.5
## 8     8   7  
## 9     9   7.5</code></pre>
<p>And here is the graph:</p>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">linear_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">X6</span>, x <span class="op">=</span> <span class="va">X5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="sem_book_files/figure-html/unnamed-chunk-34-1.png" width="672"></div>
<p>Now the correlation:</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">X5</span>, <span class="va">X6</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>It is 1, as expected.</p>
<p>What about a perfectly straight line with a negative slope?</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X7</span> <span class="op">&lt;-</span> <span class="fl">5</span> <span class="op">-</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">X5</span>
<span class="va">X7</span></code></pre></div>
<pre><code>## [1] 4.8 4.6 4.4 4.2 4.0 3.8 3.6 3.4 3.2</code></pre>
<p>Throw this new variable into the tibble we already have (for convenience). To explain the syntax below, the <code>%&gt;%</code> symbol is called a “pipe” and it tells R to pass the <code>linear_data</code> tibble on to the next row to process it. And the processing itself is dictated by the <code>bind_cols</code> command which tells R to “bind a new column” to the tibble. The part that says <code>X7 = X7</code> may be a little confusing. It says to add the new column <code>X7</code>, but also still call it <code>X7</code>.</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">linear_data</span> <span class="op">&lt;-</span> <span class="va">linear_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_cols</a></span><span class="op">(</span>X7 <span class="op">=</span> <span class="va">X7</span><span class="op">)</span>
<span class="va">linear_data</span></code></pre></div>
<pre><code>## # A tibble: 9 × 3
##      X5    X6    X7
##   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     1   3.5   4.8
## 2     2   4     4.6
## 3     3   4.5   4.4
## 4     4   5     4.2
## 5     5   5.5   4  
## 6     6   6     3.8
## 7     7   6.5   3.6
## 8     8   7     3.4
## 9     9   7.5   3.2</code></pre>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">linear_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">X7</span>, x <span class="op">=</span> <span class="va">X5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="sem_book_files/figure-html/unnamed-chunk-38-1.png" width="672"></div>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">X5</span>, <span class="va">X7</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -1</code></pre>
<p>Again, that is what we expected.</p>
<p>What happens if we plot random data? The <code>runif</code> command just chooses random numbers uniformly between 0 and 1.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Sean’s brain always want to parse this command as “run if”. Run if what? No, no, it’s “r unif”.&lt;/p&gt;"><sup>12</sup></a></p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span>
<span class="va">X8</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">20</span><span class="op">)</span>
<span class="va">X9</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">20</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X8</span></code></pre></div>
<pre><code>##  [1] 0.113703411 0.622299405 0.609274733 0.623379442 0.860915384 0.640310605
##  [7] 0.009495756 0.232550506 0.666083758 0.514251141 0.693591292 0.544974836
## [13] 0.282733584 0.923433484 0.292315840 0.837295628 0.286223285 0.266820780
## [19] 0.186722790 0.232225911</code></pre>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X9</span></code></pre></div>
<pre><code>##  [1] 0.31661245 0.30269337 0.15904600 0.03999592 0.21879954 0.81059855
##  [7] 0.52569755 0.91465817 0.83134505 0.04577026 0.45609148 0.26518667
## [13] 0.30467220 0.50730687 0.18109621 0.75967064 0.20124804 0.25880982
## [19] 0.99215042 0.80735234</code></pre>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">random_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span><span class="va">X8</span>, <span class="va">X9</span><span class="op">)</span>
<span class="va">random_data</span></code></pre></div>
<pre><code>## # A tibble: 20 × 2
##         X8     X9
##      &lt;dbl&gt;  &lt;dbl&gt;
##  1 0.114   0.317 
##  2 0.622   0.303 
##  3 0.609   0.159 
##  4 0.623   0.0400
##  5 0.861   0.219 
##  6 0.640   0.811 
##  7 0.00950 0.526 
##  8 0.233   0.915 
##  9 0.666   0.831 
## 10 0.514   0.0458
## 11 0.694   0.456 
## 12 0.545   0.265 
## 13 0.283   0.305 
## 14 0.923   0.507 
## 15 0.292   0.181 
## 16 0.837   0.760 
## 17 0.286   0.201 
## 18 0.267   0.259 
## 19 0.187   0.992 
## 20 0.232   0.807</code></pre>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">random_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">X9</span>, x <span class="op">=</span> <span class="va">X8</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="sem_book_files/figure-html/unnamed-chunk-44-1.png" width="672"></div>
<div class="rmdnote">
<p>What do you guess is the correlation between <span class="math inline">\(X_{8}\)</span> and <span class="math inline">\(X_{9}\)</span>?</p>
<p>Now calculate it using R? Did you get the <em>exact</em> answer you guessed? If not, why not?</p>
</div>
<p>What about data that follows a perfect mathematical relationship that is not a straight line? For example, here is a part of a parabola.</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X10</span> <span class="op">&lt;-</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="va">X5</span><span class="op">^</span><span class="fl">2</span>
<span class="va">X10</span></code></pre></div>
<pre><code>## [1] 0.1 0.4 0.9 1.6 2.5 3.6 4.9 6.4 8.1</code></pre>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nonlinear_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span><span class="va">X5</span>, <span class="va">X10</span><span class="op">)</span>
<span class="va">nonlinear_data</span></code></pre></div>
<pre><code>## # A tibble: 9 × 2
##      X5   X10
##   &lt;int&gt; &lt;dbl&gt;
## 1     1   0.1
## 2     2   0.4
## 3     3   0.9
## 4     4   1.6
## 5     5   2.5
## 6     6   3.6
## 7     7   4.9
## 8     8   6.4
## 9     9   8.1</code></pre>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">nonlinear_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">X10</span>, x <span class="op">=</span> <span class="va">X5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="sem_book_files/figure-html/unnamed-chunk-47-1.png" width="672"></div>
<p>Now for the correlation:</p>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">X5</span>, <span class="va">X10</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 0.975281</code></pre>
<p>This is a large correlation, but it is not exactly 1, even though the points follow a precise mathematical relationship. That relationship is not linear.</p>
<p>Here’s a fascinating example. For this, we’ll want a parabola that goes down and then up.</p>
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X11</span> <span class="op">&lt;-</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="op">(</span><span class="va">X5</span> <span class="op">-</span> <span class="fl">5</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span>
<span class="va">X11</span></code></pre></div>
<pre><code>## [1] 8.0 4.5 2.0 0.5 0.0 0.5 2.0 4.5 8.0</code></pre>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nonlinear_data</span> <span class="op">&lt;-</span> <span class="va">nonlinear_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_cols</a></span><span class="op">(</span>X11 <span class="op">=</span> <span class="va">X11</span><span class="op">)</span>
<span class="va">nonlinear_data</span></code></pre></div>
<pre><code>## # A tibble: 9 × 3
##      X5   X10   X11
##   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     1   0.1   8  
## 2     2   0.4   4.5
## 3     3   0.9   2  
## 4     4   1.6   0.5
## 5     5   2.5   0  
## 6     6   3.6   0.5
## 7     7   4.9   2  
## 8     8   6.4   4.5
## 9     9   8.1   8</code></pre>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">nonlinear_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">X11</span>, x <span class="op">=</span> <span class="va">X5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="sem_book_files/figure-html/unnamed-chunk-51-1.png" width="672"></div>
<div class="rmdnote">
<p>Before looking at the answer, what is your guess for the correlation between <span class="math inline">\(X_{5}\)</span> and <span class="math inline">\(X_{11}\)</span>?</p>
<p>Now calculate the correlation in R.</p>
<p>Again, there’s a perfect mathematical relationship between these two variables. They are most definitely associated. So why is the correlation 0?</p>
</div>
<p>Recall the earlier promise to discuss <a href="#Rule11"><strong>Rule 11</strong></a>. If two variables are independent, then their covariance is zero, and, therefore, their correlation is also zero. However, this rule doesn’t work the other way around. The claim is that knowing the covariance/correlation is zero does not imply (necessarily) that the two variables are independent. Here is the promised example of that phenomenon. <span class="math inline">\(X_{5}\)</span> and <span class="math inline">\(X_{11}\)</span> have zero correlation. And yet, <span class="math inline">\(X_{5}\)</span> and <span class="math inline">\(X_{11}\)</span> are definitely <em>not</em> independent.</p>
<p>This is important enough for a fancy box:</p>
<div class="rmdimportant">
<p><strong>When you see that the correlation between two variables is zero or near zero, be careful not to conclude that the variables are independent.</strong></p>
</div>
<p>A zero or near-zero correlation indicates only the lack of a <em>linear</em> association between two variables. There may be nonlinear associations. That’s why it’s always a good idea to graph your data.</p>
<p>Real data is, of course, much messier and it’s just not possible to have perfect correlations between two variables measured out there in the real world. (If you do find a perfect correlation between two columns of your data, chances are that you either recorded the same column twice, or the second column is some simple transformation of first column, like multiplying every value by the same number or something like that.)</p>
<p>Here is a plot of the temperature (degrees Fahrenheit) and wind speed (mph) from the New York air quality data set.</p>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">airquality</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">Temp</span>, x <span class="op">=</span> <span class="va">Wind</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="sem_book_files/figure-html/unnamed-chunk-52-1.png" width="672"></div>
<div class="rmdnote">
<p>Just looking at the scatterplot (without calculating anything), is the correlation between these two variables positive or negative? Try guessing the exact value of the correlation.</p>
<p>Now calculate the exact value of the correlation to see how close you were.</p>
</div>
<div class="rmdnote">
<p>If you want some practice with looking at scatterplots and guessing the correlation, try this online game:</p>
<p><a href="http://guessthecorrelation.com/">Guess the Correlation</a></p>
<p>Turn up the sound! If the whole class plays at the same time, your classroom will sound like an arcade. Compete with your classmates to see who can get the high score.</p>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="variance.html"><span class="header-section-number">2</span> Variance</a></div>
<div class="next"><a href="simple.html"><span class="header-section-number">4</span> Simple regression</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#covariance"><span class="header-section-number">3</span> Covariance</a></li>
<li><a class="nav-link" href="#covariance-calculating"><span class="header-section-number">3.1</span> Calculating covariance</a></li>
<li><a class="nav-link" href="#covariance-r"><span class="header-section-number">3.2</span> Calculating covariance in R</a></li>
<li><a class="nav-link" href="#covariance-rules"><span class="header-section-number">3.3</span> Covariance rules</a></li>
<li><a class="nav-link" href="#covariance-correlation"><span class="header-section-number">3.4</span> Correlation</a></li>
<li><a class="nav-link" href="#covariance-standardized"><span class="header-section-number">3.5</span> Covariance with standardized data</a></li>
<li><a class="nav-link" href="#covariance-visualizing"><span class="header-section-number">3.6</span> Visualizing correlation</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/VectorPosse/sem_book/blob/main/03-Covariance.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/VectorPosse/sem_book/edit/main/03-Covariance.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Demystifying Structural Equation Modeling</strong>" was written by Jonathan Amburgey and Sean Raleigh, Westminster College (Salt Lake City, UT). It was last built on 2022-05-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
